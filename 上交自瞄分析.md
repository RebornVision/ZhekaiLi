# 上海交通大学 步兵自瞄和英雄反前哨视觉算法 # 
## 求装甲板朝向角 ##
PNP求坐标（vtec）效果好，求朝向角（rvec）效果不好，原因是在0度左右的突变。<br>

### 解决思路一：
降自由度，以yaw为自变量，只利用pnp的坐标秋tvec而不用rvec，利用已知roll和pitch，将装甲板重新从陀螺仪坐标系投影到相机坐标系，以投影装甲板四边形和识别装甲板四边形的差为应变量。<br> 
得到的差-yaw曲线是一个下凸函数。下凸函数的极低点可以用三分法或者梯度下降法求，极低点的x就是装甲板朝向角yaw。配合神经网络识别，yaw在0度附近，跳変在5度以内，平均误差1-2度。<br>
世界坐标系到重投影的时间开销较大，可以用phi优选法优化三分法降低一半的时间。<br>

### 解决思路二：
使用传统视觉识别以保证识别装甲板框出矩形的精度，然后使用cv::solvePnP(...,cv::SOLVEPNP_IPPE)：即利用装甲板四个点同平面优化pnp的性能。这能减少一些跳変。<br>
神经网络识别的精度似乎较差，使用epnp也没什么用。

## 求陀螺运动方程 ##

### 解决思路一 ###
求得yaw以后，在同一个机器人的两个装甲板同时出现时可以用几何法反向延长求出机器人的长轴和短轴长度，以及长轴短轴装甲板的z轴差。将三个量丢入观测量和预测量均为1*1的卡尔曼滤波器。维护当前看到的装甲板是长轴还是短轴，利用上述三个量可以在任意一帧求出机器人中心，将中心xyz分别丢入观测量为1*1,预测量为[坐标，速度]的滤波器，这时就可以得到对装甲板的运动预测序列。<br>
视觉最重要的是要得到运动序列

### 解决思路二 ###
求得朝向yaw以后，以陀螺仪球面坐标系下的yaw，pitch，row作为观测量，将长短轴半径纳入扩展卡尔曼滤波器的预测量，用ceres自动求导得出相应的近似线性的转移矩阵的方差矩阵。
2021年上交开源的自瞄，不再使用卡尔曼滤波器，而是扩展卡尔曼滤波。
这样可以省去几何法求半径的过程，相比几何法求半径更稳定。

### 运动方程 ###

#### 预测量 ####
机器人中心坐标xc，yc，zc <br>
机器人中心速度xv，yv，zv <br>
装甲板z轴偏移量zp <br>
装甲板旋转半径和速度 θ θv
装甲板半径r

#### 观测量 ####
yaw pitch distance orientation_yaw

#### 预测量转观测量measure ####
x'=xc+rcosθ, y'=yc+sinθ, z'=zc+zp, 将x‘,y',z'转为球面坐标系即可，另有orientation_yaw=0

#### 预测方程predict ####

## 打击目标选择 ##
步兵追求高速打击，利用各段延迟，追踪朝向角为-orientation_angle到+orientation_angle（正对相机定义为0）的装甲板位置。步兵在打击120转以上的陀螺的时候受限于云台跟踪斜坡函数的性能，也可以设置orientation_angle参数为0。<br>
英雄追求高命中率，计算orientation_angle = 0 时装甲板位置。<br>
各种优化，以及考虑各段延迟、子弹飞行在内的打击目标求解可以看之后放在交龙博客上的代码。<br>
sjtu-robomaster-team.github.io

## 自瞄效果测试 ##
考虑自身小陀螺、射频、敌人转速，测试命中率。<br>
射频是反陀螺重要指标（对于我们而言或许小陀螺转速也是）

## 画自己即将打出的子弹流 ##
### 延迟组成 ###
程序中数值是agx内置时间轴下的。<br>
一帧图像最多对应一个信号，一个信号最多对应一次发射。
|名称|时间点|说明|
|:-|:-|:-|
|img|相机曝光时间的中点||
|predict|经过神经网络，预测器处理完成后，开始进行运动和目标解算的时间点|在目标解算的时候，只能预测目前解算后面的几个延迟，前面的延迟可以在本帧测量|
|send|预测进程结束，准备发出信号的时间点|分离出这个时间点是因为这个时间点可以测量|
|control|电控接受到信号后，电机开始运动的时间点||
|fire|信号所指示的子弹发射的时间点|control到fire的间隔包括传动需要时间、子弹下落和加速需要时间|
|hit|信号所指示的子弹击中的时间点||
实验发现，control到fire确实存在几十毫秒的延迟，我们无法保证电控收到control命令的时候，该命令的子弹同时发射。<br>
不妨假设子弹始终在发射，就像发射水流一样。由于视觉总是可以让电控在control时间点达到命令的位置，我们希望control时间点发出的子弹可以击中目标。<br>
我们发现所有信号均是基于以下模型：当电控开始处理该信号时，即在control时间点，电机能立即达到信号所指向的角度（这是通过电控的跟随算法实现的对斜坡函数的良好跟随）。图像时间为img_t的信号，将会给出img_t+img_to_control_latency()时刻的期望转角。因此我们查询拥有的img_t为fire_t-img_to_control_latency_的信号。用它的发射参数即可模拟弹道。

## 英雄打击前哨站 ##
### 测距 ###
1.长焦+PNP
2.单点激光

### 弹道解算 ###
详见 B站 RMUC 2023青工会技术答辩-上海交通大学-步兵自瞄和英雄反前哨视觉算法 https://www.bilibili.com/video/BV1vX4y1W7U7/?spm_id_from=333.337.search-card.all.click&vd_source=497d4f2b8e0a0dec0cde19b2e5e09b2a

### 细节修正 ###
1.激光——相机陀螺仪修正<br>
2.相机——激光安装修正<br>
3.机械发射修正<br>

## 视觉反旋转前哨 ##
1.前哨转速固定，陀螺中心固定，陀螺半径固定 <br>
2.英雄的云台可能相应较慢。<br>

### 算法概述 ###
1.神经网络装甲板识别<br>
2.过滤顶板<br>
3.取要处理的一块装甲板，进行角度预测，识别装甲板切换，进行卡尔曼滤波估计实际角速度（滤波器1）。<br>
装甲板切换就直接判断相邻帧的装甲板距离，大于阈值了就切换为下一个。<br>
这一步可以确定正反转，确定实际速度是0.4r/s还是0.2r/s。<br>
4.pnp预测位置，反向延长得到前哨战陀螺中心位置，丢入位置滤波器。<br>
5.陀螺中心延长得到正对的一块装甲板的位置，进行弹道解算给出移动指令。<br>
6.预测Δt后装甲板的角度(滤波器2)，若与正对的位置角度的差值小于阈值，则给发射指令。<br>
滤波器2为理想滤波器，预测仅使用0.4r/s或0.2/s的转速。预测结果更稳定。<br>
<br>
该算法的前提是机械发射散度好，发射延迟稳定<br>
该算法调参只需要调落点和Δt<br>
实际在过滤顶板时需考虑诸多细节，例如绿灯识别结果会跳帧，装甲板识别结果会有顶、底、顶+底三种情况<br>
有时由于各种原因，装甲板识别的结果也会跳帧漏帧，很可能导致发不出弹<br>
解决方法是可以在没有识别结果时也利用滤波器已经积累的数据进行预测和发弹

## 评委点评 ##
1.上交神经网络训练导入的是640*380分辨率的rgb图，评委建议尝试raw格式文件，因为raw图中的丰富信息可能是神经网络真正需要的。<br>

